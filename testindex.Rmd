---
title: "Musicology-Portfolio"
author: "Finn Duijvestijn"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    self_contained: false
    theme:
      version: 5

---

```{r}
library(tidyverse)
library(spotifyr)
library(flexdashboard)
library(ggplot2)
library(plotly)
library(compmus)

library(grid)
library(gridExtra)
library(cowplot)
library(patchwork)

library(ggdendro)
library(heatmaply)
library(protoclust)
library(tidymodels)
library(kknn)

Sys.setenv(SPOTIFY_CLIENT_ID="34c9d0d698064bf886a78b343db5445b")
Sys.setenv(SPOTIFY_CLIENT_SECRET="d0e93595f1ee411bb21938c5cb50d247")

access_token <- get_spotify_access_token()

pop <- get_playlist_audio_features("", "2AipD5zTjWWM13wk2hZmej")
phonk <- get_playlist_audio_features("", "37i9dQZF1DWWY64wDtewQt")
rap <- get_playlist_audio_features("", "37i9dQZF1DX76t638V6CA8")

awards <-
  bind_rows(
    pop |> mutate(category = "Pop"),
    phonk |> mutate(category = "Phonk"),
    rap |> mutate(category = "Rap")
    
  )
```

Introduction {.storyboard data-icon="ion-ios-home"}
=========================================

### Exploring the Unique Sounds: A Comparison of Three Distinct Music Genres 
<font style="font-size: 30px">My Corpus choice</font>

My corpus consists of a collection of songs from various genres including mainly Pop, Rap, and Phonk (which is a sub

***



Classification {.storyboard data-icon="fa-pie-chart"}
=========================================

### Dendogram & heatmap

```{r startup}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  
get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
} 


indie <-
  bind_rows(
    pop |> mutate(playlist = "Pop") |> slice_head(n = 20),
    phonk |> mutate(playlist = "Phonk") |> slice_head(n = 20),
    rap |> mutate(playlist = "Rap") |> slice_head(n = 20),
  ) |> 
  add_audio_analysis()

indie_features <-
  indie |>
  mutate(playlist = factor(playlist)) |>
  mutate(segments = map2(segments, key, compmus_c_transpose)) |>
  mutate(
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

indie_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = indie_features
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors())

indie_cv <- indie_features |> vfold_cv(5)

knn_model <-
  nearest_neighbor(neighbors = 1) |>
  set_mode("classification") |> 
  set_engine("kknn")
```


```{r halloween}
halloween <-
  get_playlist_audio_features("", "2AipD5zTjWWM13wk2hZmej") |>
  slice(1:20) |>
  add_audio_analysis() |>
  mutate(segments = map2(segments, key, compmus_c_transpose)) |>
  mutate(
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))
halloween_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = halloween
  ) |>
  step_range(all_predictors()) |>
  prep(halloween |> mutate(track.name = str_trunc(track.name, 20))) |>
  juice() |>
  column_to_rownames("track.name")
ggheatmap(
  halloween_juice,
  hclustfun = protoclust,
  dist_method = "manhattan")
```

***

**Explanation** 

The dendrogram and heatmap breaks the Pop playlist into small clusters and shows us which musical features are most intense for each song. These musical characteristics/features are on the x-axis and the songs themselves can be seen on the y-axis. It consist of the first 20 songs of the Pop playlist since it would not be readable to apply a dendrogram for the entire playlist. Since these songs all belong to the same genre/playlist I wanted to see if the algorithm could subdivide them even more. 

Something I found interesting, is that it doesn't seem that the algorithm takes into account which artist is on the song. This is because it can be seen that Post Malone has namely two songs within the dendrogram which are not on the same subcluster: "Wow" and "Goodbyes". Although both "Wow" and "Goodbyes" were created by Post Malone and belong to different subclusters within the same main cluster, their shared membership in the main cluster still suggests a degree of relationship between them. 


### Ranking important features

```{r features}

forest_model <-
  rand_forest() |>
  set_mode("classification") |> 
  set_engine("ranger", importance = "impurity")
indie_forest <- 
  workflow() |> 
  add_recipe(indie_recipe) |> 
  add_model(forest_model) |> 
  fit_resamples(
    indie_cv, 
    control = control_resamples(save_pred = TRUE)
  )

# indie_forest |> get_pr()

workflow() |> 
  add_recipe(indie_recipe) |> 
  add_model(forest_model) |> 
  fit(indie_features) |> 
  pluck("fit", "fit", "fit") |>
  ranger::importance() |> 
  enframe() |> 
  mutate(name = fct_reorder(name, value)) |> 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")
```


***

**Explanation**

Random forests are a powerful variant of the decision-tree. Although no single classifier works best for all problems, in practice, random forests are among the best-performing off-the-shelf algorithms for many real-world use cases. Random forests also give us a ranking of feature importance, which is a measure of how useful each feature in the recipe was for distinguishing the ground-truth classes.

Since random forests also give us a ranking of feature importance, I decided to use this to find out which features ranked highest for distinguishing whether a song was part of the Pop, Phonk or Rap genre. As can be seen there are two features which seem to have a major impact on deciding to which genre a song belongs: Instrumentalness and duration. This makes sense since almost all Phonk songs for example have a relatively short duration of the song, but are very instrumental. Interestingly the rest of the rest of the features seem to not play as big of a role in this decision.



### Confidence Matrix

```{r workouts}
indie_knn <- 
  workflow() |> 
  add_recipe(indie_recipe) |> 
  add_model(knn_model) |> 
  fit_resamples(indie_cv, control = control_resamples(save_pred = TRUE))

ConfMatAll <- indie_knn |> get_conf_mat()
AllPrecision <- indie_knn |> get_pr()

ConfMatAll |> autoplot(type = "heatmap")
```


***
**Explanation**

Based on the features which can be seen on the previous page, I made a model to predict whether a song belongs in the Pop genre, the Phonk genre or the Rap genre. Again the features that were the most important were: Instrumentalness and duration. 

Here you can see how well the model did; the number in the cells show for every combination (the three true categories and how the three categories were predicted) how often this was the case. For example, the first value (upper left corner) shows the number of times the model predicted correctly that a song was from the Phonk genre, the value immediately below shows for every Phonk song the number of times it predicted it was a Pop song and underneath that is the times that it predicted it as a Rap song. Surprisingly classifying Pop songs seems to be the easiest for the algorithm. Songs from both the Phonk and Rap genre seem to be harder to classify for the algorithm since these have a lot less correct predictions.

Below is a table of the actual evaluation metrics showing the performance of the classifier.

**Evaluation model using all features**  

```{r}
AllPrecision %>% knitr::kable()
```

Precision is the proportion of accurately predicted songs from all songs the model predicted to be from that genre. Recall shows from all songs that are actually from that genre the proportion that got predicted accurately. 



### Two most important features & Genre

```{r}
indie_features |>
  ggplot(aes(x = duration, y = instrumentalness, colour = playlist, size = energy)) +
  geom_point(alpha = 0.8) +
  scale_color_viridis_d() +
  labs(
    x = "Duration",
    y = "Instrumentalness",
    size = "Energy",
    colour = "Playlist"
  )
```

***

**Explanation**

Since the feature ranking showed us that Instrumentalness and Duration were the two most important features for classifying a song to be within one of the three genres: Pop, Phonk and Rap, I decided to make a more interpretable plot to be able to see the actual differences between the genres for those exact features.

Interestingly Rap songs seem to have almost no instrumentalness on average. What surprised me even more is that besides only three Pop songs, it also seems that Pop songs have very low instrumentalness on average. There does not seem to be a lot of distinction between the duration of these two genres as well. So basically both Rap and Pop songs have low instrumentalness while also having a evenly distributed song duration. This is probably why the classifier finds it hard to predict and classify between these genres.

However to see that Phonk had a high instrumentalness and short duration on average was not surprising to me, like already mentioned in on the previous pages.


What did I find {.storyboard data-icon="fa-spotify"}
=========================================

### Conclusion {data-commentary-width=450}

ent genres and their respective subcultures.

***

```{r picture2, out.width = '100%', out.height = '100%'}
knitr::include_graphics("pics/pop.jpg")
knitr::include_graphics("pics/phonk.jpg")
knitr::include_graphics("pics/rap.jpg")
```


